---
title: "Logistic Regression"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
#Import packages
library(tidyverse)
library(caret)
library(ISLR)
library(dplyr)
library(Boruta)
library(leaps)
library(MASS)
library(ggeffects)
library(ggplot2)
```


```{r}
#Read the dataset
Rice_data <- read.csv('Rice_Commeo_Osmancik.csv', header=TRUE)
```


```{r}
#View a glimpse of the data and dtypes and convert to numeric
glimpse(Rice_data)
Rice_data$Area = as.numeric(Rice_data$Area)
Rice_data$Convex_Area = as.numeric(Rice_data$Convex_Area)
```
```{r}
head(Rice_data)
```

```{r}
#Plot the class variable
ricePlot <- ggplot(Rice_data, aes(x=Class, fill = Class)) + geom_bar() + ylim(0, 2500)
ricePlot
```

```{r}
#Convert the class variable to binary values where Osmancik=0 and Cammeo=1

Rice_data$Class <- as.factor(Rice_data$Class)
Rice_data <- Rice_data %>% 
  mutate(Class = recode(Class, 
                    "Osmancik" = "0", 
                    "Cammeo" = "1")) 

str(Rice_data)  
```

```{r}
#count for each class variable value
Class_count <- count(Rice_data, Class)
Class_count
```

```{r}
#Check correlation before deciding whether to use PCA
cor(Rice_data[,-8])
```
```{r}
#The most highly correlated variables are Area with Convex_Area as well as Perimeter and Major_Axis_Length.
#So we can check the variances between these pairs to see which should be removed.
var(Rice_data$Area)
var(Rice_data$Convex_Area)
var(Rice_data$Perimeter)
var(Rice_data$Major_Axis_Length)
#we can remove Area and Major_Axis_Length when building our models.
```
```{r}
Rice_data
```

```{r}
New_Rice_data <- subset(Rice_data, select = c(Perimeter, Minor_Axis_Length, Eccentricity, Convex_Area, Extent, Class))
```


```{r}
#There are many highly correlated values so PCA should be performed
pc_Rice <- princomp(New_Rice_data[,-6], cor = TRUE, score = TRUE)
summary(pc_Rice)
```
```{r}
#Plot the variances
plot(pc_Rice)
pc_Rice$loadings

#The plot shows us the first three components are significant (PCA will be implemented for one of the lr models)
```

```{r}
#Boruta feature selection
#1. Perform a Boruta search to identify variables
set.seed(123)
boruta_Rice <- Boruta(Class ~ ., data = New_Rice_data, doTrace=2)
```
```{r}
#2. check the boruta output
names(boruta_Rice)
```
```{r}
#3. obtain the significant variables
roughFixMod <- TentativeRoughFix(boruta_Rice)
boruta_signif <- getSelectedAttributes(boruta_Rice, withTentative = FALSE)
print(boruta_signif)
```
```{r}
#4. Check the importance of the variables
imps <- attStats(roughFixMod)
imps2 = imps[imps$decision != 'Rejected', c('meanImp','decision')]
imps2[order(-imps2$meanImp), ]
```


```{r}
#4. Plot the importance of the variables
plot(boruta_Rice, cex.axis=0.58, las=2, xlab="", main="Variable Importance")
```
```{r}
#Get a list of the final selected variables
finalvars <- getSelectedAttributes(boruta_Rice, withTentative = FALSE)
finalvars
#All variables were determined to be important for the predictive analysis
```
```{r}
#Remove Area and Major_Axis_Length as they are highly correlated
New_Rice_data <- subset(Rice_data, select = c(Perimeter, Minor_Axis_Length, Eccentricity, Convex_Area, Extent, Class))
str(New_Rice_data)
```

```{r}
#implement k-fold cv and build the logistic regression model
set.seed(2)

fold <- createFolds(New_Rice_data$Class, k = 10)
for (f in fold) {
  train <- New_Rice_data[-f,]
  test <- New_Rice_data[f,]
}
```

```{r}
set.seed(2)
rice_lr <- train(Class ~ Perimeter + Minor_Axis_Length + Eccentricity + 
                    Convex_Area + Extent, data = train, method = "glm", 
                  family = binomial)
summary(rice_lr)
```
```{r}
set.seed(2)
rice_lr_prediction <- predict(rice_lr, test, type = 'raw') 
# gives the probability for each class
head(rice_lr_prediction)
```
```{r}
confusionMatrix(rice_lr_prediction, test$Class)
```

```{r}
#create another lr model using PCA to see if it improves the accuracy
#create another decision tree model using PCA to see if it improves the model
set.seed(2)

pca <- prcomp(train[, 1:5], scale. = T, center = T)

test.zspace <- predict(pca, newdata = test[, 1:5])
pca.train.df <- as.data.frame(pca$x)
pca.train.df$Class <- train[,6]

lr.pca.model <- train(Class ~., data = pca.train.df, method = "glm", 
                  family = binomial)

pca.test.df <- as.data.frame(test.zspace)
pca.test.df$Class <- test[, 6]
lr.pca.pred <- predict(lr.pca.model, pca.test.df[, 1:5], type='raw')

summary(lr.pca.model)

confusionMatrix(lr.pca.pred, test[, 6])
```


```{r}
#Perform K-fold Cross-Validation 

#1. choose the cv method
ctrl <- trainControl(method = "cv", number = 10, savePredictions = TRUE)

#2. fit the regression model and use the k-fold cv to evaluate (not including Area and Major_Axis_Length)
lr_model <- train(Class ~ Perimeter + Minor_Axis_Length + Eccentricity + 
                    Convex_Area + Extent, data = Rice_data, method = "glm", 
                  family = binomial, trControl = ctrl)

summary(lr_model)
print(lr_model)
```

```{r}
#using PCA to see if it improves the model (not including Area and Major_Axis_Length)

lr_model2 <- train(Class ~ Perimeter + Minor_Axis_Length + Eccentricity + 
                     Convex_Area + Extent, data = Rice_data, method = "glm", 
                   preProcess=c("pca"), family = binomial, trControl = ctrl)
summary(lr_model2)
print(lr_model2)
```
```{r}
#Use the models to make predictions and summarize the results. 

summary(lr_model$pred)


summary(lr_model2$pred)
```

```{r}
confusionMatrix(lr_model)
```

```{r}
Sensitivity <- 39.2/(39.2+3.6)
Sensitivity
Specificity <- 54/(3.2+54)
Specificity
Prevalence <- (39.2+3.6)/(39.2+3.2+3.6+54)
Prevalence
PPV <- (Sensitivity*Prevalence)/((Sensitivity*Prevalence)+((1-Specificity)*(1-Prevalence)))
PPV
NPV <- (Sensitivity*(1-Prevalence))/(((1-Sensitivity)*Prevalence)+((Specificity)*(1-Prevalence)))
NPV
```
```{r}
tpr <- 39.2/(39.2+3.6)
tpr
```


```{r}
varImp(lr_model)
```

```{r}
ggplot(varImp(lr_model))
```
```{r}
lr_predictions <- predict(lr_model, New_Rice_data)
confusionMatrix(lr_predictions, New_Rice_data$Class)
```



Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
